{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                               text  compound    neg  \\\n",
      "0    0.0      totally disagree wait surgery bloody hospital   -0.8431  0.751   \n",
      "1    1.0  receptionist rude makes wait phone waiting 50 ...   -0.8591  0.393   \n",
      "2    2.0                              great sister handsome    0.8074  0.000   \n",
      "3    3.0  satisfied corona booster risk group go back sc...    0.8901  0.078   \n",
      "4    4.0  unfortunately lung cancer chance surviving sis...   -0.0258  0.303   \n",
      "5    5.0  broke ribs hurts lot sit emergency room waitin...   -0.8595  0.491   \n",
      "6    6.0  give birth hospital teenage mother midwives to...   -0.1779  0.201   \n",
      "7    7.0  recorded say corona total bullshit not dead dr...   -0.5938  0.321   \n",
      "8    8.0  blood tests results yet wait know always short...   -0.1882  0.185   \n",
      "9    9.0  top hospital pay 1006 euros treatment not work...    0.0000  0.264   \n",
      "10  10.0  care poor waiting time simple surgery knee two...   -0.4404  0.399   \n",
      "11  11.0      receptionist curt wait long time waiting room   -0.7906  0.667   \n",
      "12  12.0  everything well arranged 10 euros per hour par...   -0.1027  0.216   \n",
      "13  13.0  hospital still believes corona hoax muzzles ev...   -0.8126  0.552   \n",
      "14  14.0         well done nothing complain aftercare order    0.4956  0.000   \n",
      "15  15.0              casually diagnose treatment make easy    0.5574  0.000   \n",
      "16  16.0                 came sex change operation hurt lot   -0.5267  0.405   \n",
      "17  17.0                         say anything good catering    0.4404  0.000   \n",
      "18  18.0  arm broken well helped friendly staff arm stil...   -0.2263  0.376   \n",
      "19  19.0  staff looked like funeral unsociable turned ar...   -0.3612  0.370   \n",
      "20  20.0  receptionist want help dutch passport friend t...    0.8360  0.000   \n",
      "21  21.0  appendix come done well doctor sisters friendl...    0.8999  0.000   \n",
      "22  22.0  3 children born midwives little less nice fort...    0.6476  0.143   \n",
      "23  23.0  gave birth diabetes hospital addition wanted d...   -0.1027  0.104   \n",
      "24  24.0  corona place allowed even though breathe almos...    0.5709  0.152   \n",
      "25  25.0  go ic corona go room mark rutte hugo de jonge ...   -0.5994  0.170   \n",
      "26  26.0  mentally disabled son 21 helped bedwetting unf...   -0.5106  0.335   \n",
      "27  27.0                         mommy went never came back    0.0000  0.000   \n",
      "28  28.0        sent doctor speech therapy child lisps even   -0.1280  0.200   \n",
      "29  29.0  could longer smell corona sent icu experts nic...    0.4215  0.000   \n",
      "30  30.0  mother mri scan yesterday everything going gre...    0.8316  0.000   \n",
      "31  31.0  toe broken yesterday wanted go hospital asap s...   -0.7003  0.396   \n",
      "32  32.0  doctor laptop battery dead wait take battery b...   -0.8834  0.632   \n",
      "33  33.0            think hospital pritty like sisters nice    0.6486  0.000   \n",
      "34  34.0  mole apparently cancer dermatologist doctor sa...   -0.7579  0.485   \n",
      "35  35.0  watch behind schedule late investigation going...    0.0000  0.000   \n",
      "36  36.0                              top hospital die cold   -0.4767  0.506   \n",
      "37  37.0     cunt cunt cunt cunt cunt hospital nose crooked   -0.9432  0.842   \n",
      "38  38.0                      wife cancer annoying everyone   -0.7964  0.780   \n",
      "39  39.0  tire flat not even allowed fix tire hospital 1...   -0.1027  0.135   \n",
      "40  40.0  spent three hours walking pharmacy waiting cou...   -0.4588  0.300   \n",
      "41  41.0  went emergency room last friday son swallowed ...    0.6486  0.141   \n",
      "42  42.0  appendix removed good aftercare nice sisters p...    0.2040  0.180   \n",
      "43  43.0  gave birth eighth child first wanted give birt...    0.4404  0.058   \n",
      "44  44.0  broke arm well helped staff x ray department n...    0.8979  0.089   \n",
      "45  45.0  sterilized operation not pleasant addition wif...    0.2495  0.126   \n",
      "46  46.0  came draw blood man service desk uncooperative...   -0.4215  0.157   \n",
      "47  47.0  tasty sandwich chicken breast nice girls great...    0.7845  0.000   \n",
      "48  48.0     jaw surgeon quick painful got good explanation    0.0000  0.269   \n",
      "49  49.0               went sleep issues fell asleep course   -0.3182  0.315   \n",
      "\n",
      "      neu    pos  \n",
      "0   0.249  0.000  \n",
      "1   0.525  0.082  \n",
      "2   0.120  0.880  \n",
      "3   0.411  0.510  \n",
      "4   0.350  0.347  \n",
      "5   0.406  0.103  \n",
      "6   0.619  0.180  \n",
      "7   0.528  0.151  \n",
      "8   0.677  0.139  \n",
      "9   0.566  0.170  \n",
      "10  0.392  0.209  \n",
      "11  0.333  0.000  \n",
      "12  0.603  0.181  \n",
      "13  0.448  0.000  \n",
      "14  0.487  0.513  \n",
      "15  0.395  0.605  \n",
      "16  0.595  0.000  \n",
      "17  0.508  0.492  \n",
      "18  0.303  0.321  \n",
      "19  0.444  0.185  \n",
      "20  0.447  0.553  \n",
      "21  0.333  0.667  \n",
      "22  0.555  0.302  \n",
      "23  0.833  0.062  \n",
      "24  0.572  0.276  \n",
      "25  0.830  0.000  \n",
      "26  0.542  0.123  \n",
      "27  1.000  0.000  \n",
      "28  0.800  0.000  \n",
      "29  0.797  0.203  \n",
      "30  0.443  0.557  \n",
      "31  0.440  0.164  \n",
      "32  0.368  0.000  \n",
      "33  0.430  0.570  \n",
      "34  0.351  0.164  \n",
      "35  1.000  0.000  \n",
      "36  0.260  0.234  \n",
      "37  0.158  0.000  \n",
      "38  0.220  0.000  \n",
      "39  0.865  0.000  \n",
      "40  0.700  0.000  \n",
      "41  0.486  0.373  \n",
      "42  0.556  0.264  \n",
      "43  0.784  0.159  \n",
      "44  0.413  0.498  \n",
      "45  0.701  0.173  \n",
      "46  0.843  0.000  \n",
      "47  0.465  0.535  \n",
      "48  0.463  0.269  \n",
      "49  0.685  0.000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import (GoogleTranslator,\n",
    "                             PonsTranslator,\n",
    "                             LingueeTranslator,\n",
    "                             MyMemoryTranslator,\n",
    "                             YandexTranslator,\n",
    "                             single_detection,\n",
    "                             batch_detection)\n",
    "import nltk\n",
    "import string as st\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import CleanupFunctions as clean\n",
    "import AddedWords\n",
    "\n",
    "# Haalt info uit csv op.\n",
    "dfDutch = pd.read_csv(\"CSVFiles/Mock-updata.csv\", sep=';')\n",
    "\n",
    "dfSentiment = pd.DataFrame.from_dict({\n",
    "    \"id\":[],\n",
    "    \"text\": [],\n",
    "    \"compound\": [],\n",
    "    \"neg\":[],\n",
    "    \"neu\":[],\n",
    "    \"pos\":[],\n",
    "})\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "index = 0\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "# Update de woordenlijst, met zelftoegevoegde woorden en het sentiment, bron: https://ithaka.github.io/tdm-notebooks/sentiment-analysis-with-vader.html\n",
    "sia.lexicon.update(AddedWords.added_words())\n",
    "\n",
    "#Loop die er voor zorgt dat alle vertaalde reviews wordt uitgeprint\n",
    "for col_name, review in dfDutch.iterrows():\n",
    "    translated = GoogleTranslator(source='dutch', target='english').translate(text=dfDutch.loc[col_name]['Tekst'])\n",
    "    textlowercase = clean.convert_to_lowercase(translated)\n",
    "    textclean = clean.punc_clean(textlowercase)\n",
    "    textstopword = clean.remove_stopword(textclean)\n",
    "    tokenized = sent_tokenize(textstopword)\n",
    "    for line in tokenized:     \n",
    "        ss = sia.polarity_scores(line)\n",
    "        dfTemp = pd.DataFrame.from_dict({\n",
    "                            \"id\":[col_name],\n",
    "                            \"text\": [textstopword],\n",
    "                            \"compound\": [ss[\"compound\"]],\n",
    "                            \"neg\":[ss[\"neg\"]],\n",
    "                            \"neu\":[ss[\"neu\"]],\n",
    "                            \"pos\":[ss[\"pos\"]],\n",
    "                            })\n",
    "        index = index + 1\n",
    "    dfSentiment = pd.concat([dfSentiment, dfTemp], ignore_index=True)\n",
    "\n",
    "print(dfSentiment)\n",
    "dfSentiment.to_csv(\"CSVFiles/MockUpDataSentiment.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "178ea9d8614524b768b73220b78679c77d0685b51afda7c8daa5d177208930c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

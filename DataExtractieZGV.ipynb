{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  compound  \\\n",
      "0      0.0  Before Corona, the phone was simply answered a...   -0.2500   \n",
      "1      1.0  Very sweet and caring staff in the mdl and sur...    0.9451   \n",
      "2      2.0  Last Friday I called the hospital for my 2 yea...   -0.6957   \n",
      "3      3.0  Costs if they call you is 60 euros per minute ...   -0.4404   \n",
      "4      4.0  Let our son with a huge thick elbow sit for mo...    0.3182   \n",
      "..     ...                                                ...       ...   \n",
      "163  163.0  A very good and efficient service in Poland ca...    0.6908   \n",
      "164  164.0  I haven't made any progress on it. Luckily I c...    0.7269   \n",
      "165  165.0                            was fine :). Thank you.    0.5106   \n",
      "166  166.0                                 Very good hospital    0.4404   \n",
      "167  167.0                                      Waiting hours    0.0000   \n",
      "\n",
      "       neg    neu    pos  \n",
      "0    0.093  0.815  0.093  \n",
      "1    0.066  0.571  0.363  \n",
      "2    0.219  0.708  0.073  \n",
      "3    0.104  0.896  0.000  \n",
      "4    0.000  0.892  0.108  \n",
      "..     ...    ...    ...  \n",
      "163  0.000  0.345  0.655  \n",
      "164  0.000  0.247  0.753  \n",
      "165  0.000  0.000  1.000  \n",
      "166  0.000  0.256  0.744  \n",
      "167  0.000  1.000  0.000  \n",
      "\n",
      "[168 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import (GoogleTranslator,\n",
    "                             PonsTranslator,\n",
    "                             LingueeTranslator,\n",
    "                             MyMemoryTranslator,\n",
    "                             YandexTranslator,\n",
    "                             single_detection,\n",
    "                             batch_detection)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import CleanupFunctions as clean\n",
    "\n",
    "# Haalt info uit csv op.\n",
    "dfDutch = pd.read_csv(\"GoogleReviewsZGVNoEmpty.csv\")\n",
    "\n",
    "dfSentiment = pd.DataFrame.from_dict({\n",
    "    \"id\":[],\n",
    "    \"text\": [],\n",
    "    \"compound\": [],\n",
    "    \"neg\":[],\n",
    "    \"neu\":[],\n",
    "    \"pos\":[],\n",
    "})\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "#Loop die er voor zorgt dat alle vertaalde reviews wordt uitgeprint\n",
    "for col_name, review in dfDutch.iterrows():\n",
    "    translated = GoogleTranslator(source='dutch', target='english').translate(text=dfDutch.loc[col_name]['review_text'])\n",
    "    textlowercase = clean.convert_to_lowercase(translated)\n",
    "    textclean = clean.punc_clean(textlowercase)\n",
    "    textstopword = clean.remove_stopword(textclean)\n",
    "    tokenized = sent_tokenize(textstopword)\n",
    "    for line in tokenized:     \n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        ss = sia.polarity_scores(line)\n",
    "        dfTemp = pd.DataFrame.from_dict({\n",
    "                            \"id\":[col_name],\n",
    "                            \"text\": [translated],\n",
    "                            \"compound\": [ss[\"compound\"]],\n",
    "                            \"neg\":[ss[\"neg\"]],\n",
    "                            \"neu\":[ss[\"neu\"]],\n",
    "                            \"pos\":[ss[\"pos\"]],\n",
    "                            })\n",
    "        index = index + 1\n",
    "    dfSentiment = pd.concat([dfSentiment, dfTemp], ignore_index=True)\n",
    "        #dfSentiment = dfSentiment.append({'id': index,'text': translated, 'compound': ss[\"compound\"], 'neg': ss[\"neg\"], 'neu': ss[\"neu\"], 'pos': ss[\"pos\"]}, ignore_index=True)\n",
    "\n",
    "print(dfSentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178ea9d8614524b768b73220b78679c77d0685b51afda7c8daa5d177208930c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

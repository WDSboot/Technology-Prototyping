{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  compound  \\\n",
      "0      0.0  corona phone simply answered rings understand ...   -0.2500   \n",
      "1      1.0  sweet caring staff mdl surgery ward got blood ...    0.9451   \n",
      "2      2.0  last friday called hospital 2 year old son con...   -0.6957   \n",
      "3      3.0  costs call 60 euros per minute watch dirty exp...   -0.4404   \n",
      "4      4.0  let son huge thick elbow sit 2 hours move said...    0.3182   \n",
      "..     ...                                                ...       ...   \n",
      "163  163.0              good efficient service poland dreamed    0.6908   \n",
      "164  164.0                      made progress luckily changed    0.7269   \n",
      "165  165.0                                         fine thank    0.5106   \n",
      "166  166.0                                      good hospital    0.4404   \n",
      "167  167.0                                      waiting hours    0.0000   \n",
      "\n",
      "       neg    neu    pos  \n",
      "0    0.093  0.815  0.093  \n",
      "1    0.066  0.571  0.363  \n",
      "2    0.219  0.708  0.073  \n",
      "3    0.104  0.896  0.000  \n",
      "4    0.000  0.892  0.108  \n",
      "..     ...    ...    ...  \n",
      "163  0.000  0.345  0.655  \n",
      "164  0.000  0.247  0.753  \n",
      "165  0.000  0.000  1.000  \n",
      "166  0.000  0.256  0.744  \n",
      "167  0.000  1.000  0.000  \n",
      "\n",
      "[168 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import (GoogleTranslator,\n",
    "                             PonsTranslator,\n",
    "                             LingueeTranslator,\n",
    "                             MyMemoryTranslator,\n",
    "                             YandexTranslator,\n",
    "                             single_detection,\n",
    "                             batch_detection)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import CleanupFunctions as clean\n",
    "\n",
    "# Haalt info uit csv op.\n",
    "dfDutch = pd.read_csv(\"CSVFiles/GoogleReviewsZGVNoEmpty.csv\")\n",
    "\n",
    "dfSentiment = pd.DataFrame.from_dict({\n",
    "    \"id\":[],\n",
    "    \"text\": [],\n",
    "    \"compound\": [],\n",
    "    \"neg\":[],\n",
    "    \"neu\":[],\n",
    "    \"pos\":[],\n",
    "})\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "#Loop die er voor zorgt dat alle vertaalde reviews wordt uitgeprint\n",
    "for col_name, review in dfDutch.iterrows():\n",
    "    translated = GoogleTranslator(source='dutch', target='english').translate(text=dfDutch.loc[col_name]['review_text'])\n",
    "    textlowercase = clean.convert_to_lowercase(translated)\n",
    "    textclean = clean.punc_clean(textlowercase)\n",
    "    textstopword = clean.remove_stopword(textclean)\n",
    "    tokenized = sent_tokenize(textstopword)\n",
    "    for line in tokenized:     \n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        ss = sia.polarity_scores(line)\n",
    "        dfTemp = pd.DataFrame.from_dict({\n",
    "                            \"id\":[col_name],\n",
    "                            \"text\": [textstopword],\n",
    "                            \"compound\": [ss[\"compound\"]],\n",
    "                            \"neg\":[ss[\"neg\"]],\n",
    "                            \"neu\":[ss[\"neu\"]],\n",
    "                            \"pos\":[ss[\"pos\"]],\n",
    "                            })\n",
    "        index = index + 1\n",
    "    dfSentiment = pd.concat([dfSentiment, dfTemp], ignore_index=True)\n",
    "        #dfSentiment = dfSentiment.append({'id': index,'text': translated, 'compound': ss[\"compound\"], 'neg': ss[\"neg\"], 'neu': ss[\"neu\"], 'pos': ss[\"pos\"]}, ignore_index=True)\n",
    "\n",
    "print(dfSentiment)\n",
    "dfSentiment.to_csv(\"CSVFiles/MockUpDataSentimentNew.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178ea9d8614524b768b73220b78679c77d0685b51afda7c8daa5d177208930c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
